# WL Graph Embedding Project

A modular and configurable implementation of the Weisfeiler-Lehman (WL) 1-dimensional algorithm for graph node labeling, embedding generation, and visualization.

This project is built using PyTorch, NetworkX, PyTorch Geometric, and provides support for:
- WL-based label computation
- Dense embedding generation using self-supervised training
- Label encodings (One-Hot, Label ID, Hex Normalization)
- Configurable YAML setup
- Modular structure for experimentation
- Graph visualization and CSV export

---

## ğŸ“ Project Structure

```
wl_project/
â”‚
â”œâ”€â”€ configs/                    # YAML config files
â”‚   â””â”€â”€ default.yaml
â”‚
â”œâ”€â”€ data/                       # Graph datasets (TUDataset, etc.)
â”‚
â”œâ”€â”€ encoders/                  # Encoding and training modules
â”‚   â”œâ”€â”€ wl_encoder.py
â”‚   
â”‚
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ WL.py                   # Weisfeiler-Lehman algorithm
â”‚   â””â”€â”€ Graph_plots.py          # Visualization and CSV export
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py               # Logger setup
â”‚
â”œâ”€â”€ wl_main.py                  # Main script (with argparse or YAML support)
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Configuration

The project is controlled via `configs/default.yaml`:

```yaml
dataset: "PROTEINS"
graph_index: 0
hash_method: "md5"
max_itr: 10
all_iterations: false
embedding_dim: 32
epochs: 50
encoding: "dense"   # Options: "dense", "label", "onehot", "hex"
```

---

## ğŸš€ How to Run

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the main script (YAML mode)

```bash
python wl_main.py
```

Or to use argparse (if implemented):

```bash
python wl_main.py --dataset PROTEINS --graph_index 0 --hash_method sha1 --encoding dense
```

---

## ğŸ§  Features

- ğŸ”„ Supports multiple hash methods: `md5`, `sha1`, `sha256`, `sha512`
- ğŸ§ª Dense self-supervised training via `nn.Embedding`
- ğŸ§¬ Hex-to-normalized float vector mapping
- ğŸ“Š Visualization with `matplotlib` and color-coded WL labels
- ğŸ“ Saves node labels, one-hot encodings, and final dense embeddings as CSV

---

## ğŸ–¼ï¸ Example Output

Graph visualization is saved in `/outputs/graph_<method>_<timestamp>.png`.

Embeddings are saved as:

- `wl_dense_embeddings_<timestamp>.csv`
- `onehot_labels_<timestamp>.csv`
- `label_ids_<timestamp>.csv`

---

## ğŸ”§ Requirements

- Python 3.8+
- torch
- torch-geometric
- networkx
- matplotlib
- pandas
- scikit-learn
- omegaconf
- tqdm

(installable via `requirements.txt`)

---

## âœ¨ Credits

Developed as part of an independent research project on Graph Neural Networks and Embedding Learning.

---

## ğŸ“„ License

MIT License. See `LICENSE` file.
