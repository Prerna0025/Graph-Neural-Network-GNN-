# WL Graph Embedding Project

A modular and configurable implementation of the Weisfeiler-Lehman (WL) 1-dimensional algorithm for graph node labeling, embedding generation, and visualization.
## ğŸ§© What is the Weisfeiler-Lehman (1-WL) Algorithm?

The 1-WL algorithm (also known as color refinement) is a graph isomorphism test used to iteratively update node labels based on their neighbors. It operates as follows:

1. Assign each node an initial label (e.g., degree or a default label).
2. At each iteration:
   - Concatenate the label of a node with sorted labels of its neighbors.
   - Apply a hash function to generate a new label.
3. Repeat until labels converge or max iterations reached.

This process encodes **structural similarity** into node labels â€” nodes with similar neighborhoods will get similar hash values.

---

## ğŸ“Œ How 1-WL Labels are Used

After computing 1-WL labels for each node, we use them for **embedding generation** in multiple ways:

- **Label Encoding**: Convert hash strings to integers.
- **One-Hot Encoding**: Convert label IDs to sparse binary vectors.
- **Hex Normalization**: Normalize hash values to float features between 0 and 1.
- **Dense Embedding (Self-Supervised)**:
    - Treat label pairs from edges as training examples.
    - Train an `nn.Embedding` model using positive (real) and negative (random) node pairs.
    - Embeddings are learned such that connected nodes are close in vector space.

---

## ğŸ”® How to Use These Embeddings

These embeddings can be:
- Used as **additional node features** in Graph Neural Networks (GNNs).
- Fed into downstream ML models for node classification or clustering.
- Visualized to understand graph structure.
- Combined with other features (e.g., node degree, community info) to boost performance.

This project is built using PyTorch, NetworkX, PyTorch Geometric, and provides support for:
- WL-based label computation
- Dense embedding generation using self-supervised training
- Label encodings (One-Hot, Label ID, Hex Normalization, Dense vector)
- Configurable YAML setup
- Modular structure for experimentation
- Graph visualization and CSV export

---

## ğŸ“ Project Structure

```
wl_project/
â”‚
â”œâ”€â”€ configs/                    # YAML config files
â”‚   â””â”€â”€ default.yaml
â”‚
â”œâ”€â”€ data/                       # Graph datasets (TUDataset, etc.)
â”‚
â”œâ”€â”€ encoders/                  # Encoding and training modules
â”‚   â”œâ”€â”€ wl_encoder.py
â”‚   
â”‚
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ WL.py                   # Weisfeiler-Lehman algorithm
â”‚   â””â”€â”€ Graph_plots.py          # Visualization and CSV export
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py               # Logger setup
â”‚
â”œâ”€â”€ wl_main.py                  # Main script (with argparse or YAML support)
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Configuration

The project is controlled via `configs/default.yaml`:

```yaml
dataset: "PROTEINS"
graph_index: 0
hash_method: "md5"
max_itr: 10
all_iterations: false
embedding_dim: 32
epochs: 50
encoding: "NormalizedValue"   # Options: "onehot", "IntegerMapping", "NormalizedValue", "DenseVector"
```

---

## ğŸš€ How to Run

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the main script (YAML mode)

```bash
python wl_main.py
```

Or to use argparse (if implemented):

```bash
python wl_main.py --dataset PROTEINS --graph_index 0 --hash_method sha1 --encoding dense
```

---

## ğŸ§  Features

- ğŸ”„ Supports multiple hash methods: `md5`, `sha1`, `sha256`, `sha512`
- ğŸ§ª Dense self-supervised training via `nn.Embedding`
- ğŸ§¬ Hex-to-normalized float vector mapping
- ğŸ“Š Visualization with `matplotlib` and color-coded WL labels
- ğŸ“ Saves node labels, one-hot encodings, and final dense embeddings as CSV

---

## ğŸ–¼ï¸ Example Output

Graph visualization is saved in `/outputs/graph_<method>_<timestamp>.png`.

Embeddings are saved as:

- `wl_dense_embeddings_<timestamp>.csv`
- `onehot_labels_<timestamp>.csv`
- `label_ids_<timestamp>.csv`

---

## ğŸ”§ Requirements

- Python 3.8+
- torch
- torch-geometric
- networkx
- matplotlib
- pandas
- scikit-learn
- omegaconf
- tqdm

(installable via `requirements.txt`)

---

## âœ¨ Credits

Developed as part of an independent research project on Graph Neural Networks and Embedding Learning.

---

## ğŸ“„ License

MIT License. See `LICENSE` file.
